{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX6TEyNxBqFUqJt9Na4yWY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunlight2018/hands_on_ml3_notebooks/blob/main/chapter_02_end_to_end.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "流程图"
      ],
      "metadata": {
        "id": "tRcj5FPffoU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 获取数据        👉 fetch_housing_data()\n",
        "2. 探索数据        👉 .head(), .info(), .describe(), .hist()\n",
        "3. 创建测试集      👉 train_test_split() + StratifiedShuffleSplit\n",
        "4. 数据清洗与预处理 👉 dropna(), SimpleImputer, Pipeline\n",
        "5. 特征工程        👉 ColumnTransformer + OneHotEncoder\n",
        "6. 训练模型        👉 fit() + predict()\n",
        "7. 模型评估        👉 RMSE, cross_val_score, 测试集验证"
      ],
      "metadata": {
        "id": "fmQynh7Xfr3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "关键词卡"
      ],
      "metadata": {
        "id": "rTbRO0Tvf5U_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "概念/模块\n",
        "说明\n",
        "\n",
        "StratifiedShuffleSplit\n",
        "分层抽样，确保训练/测试分布一致\n",
        "\n",
        "SimpleImputer\n",
        "缺失值填补（均值/中位数/众数）\n",
        "\n",
        "Pipeline\n",
        "封装数据处理步骤\n",
        "\n",
        "ColumnTransformer\n",
        "数值/类别分开处理再合并\n",
        "\n",
        "cross_val_score\n",
        "交叉验证（更稳定的评估方式）\n",
        "\n",
        "fit_transform()\n",
        "常用于数据处理链条中的一站式转换\n",
        "\n",
        "LinearRegression / RandomForestRegressor\n",
        "模型训练器\n"
      ],
      "metadata": {
        "id": "DTAHirHUgLmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧠 Hands-On ML 第三版：第二章 Colab 学习模版\n",
        "\n",
        "# ✅ 0. 环境准备\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ 1. 下载和解压数据\n",
        "def fetch_housing_data():\n",
        "    DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml3/main/\"\n",
        "    HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "    HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "    os.makedirs(HOUSING_PATH, exist_ok=True)\n",
        "    tgz_path = os.path.join(HOUSING_PATH, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(HOUSING_URL, tgz_path)\n",
        "    with tarfile.open(tgz_path) as housing_tgz:\n",
        "        housing_tgz.extractall(path=HOUSING_PATH)\n",
        "\n",
        "# ✅ 2. 加载数据\n",
        "def load_housing_data():\n",
        "    csv_path = os.path.join(\"datasets\", \"housing\", \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "fetch_housing_data()\n",
        "housing = load_housing_data()\n",
        "housing.head()\n",
        "\n",
        "# ✅ 3. 数据初探\n",
        "print(housing.info())\n",
        "print(housing[\"ocean_proximity\"].value_counts())\n",
        "print(housing.describe())\n",
        "housing.hist(bins=50, figsize=(20, 15))\n",
        "\n",
        "# ✅ 4. 划分训练/测试集（分层采样）\n",
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                                bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                                labels=[1, 2, 3, 4, 5])\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]\n",
        "\n",
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
        "\n",
        "# ✅ 5. 分离特征和标签\n",
        "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
        "\n",
        "# ✅ 6. 数值列预处理：缺失值填补 + 标准化\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "housing_num = housing.select_dtypes(include=[np.number])\n",
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"std_scaler\", StandardScaler()),\n",
        "])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
        "\n",
        "# ✅ 7. 数值+类别列预处理\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "num_attribs = list(housing_num.columns)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_attribs),\n",
        "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "\n",
        "# ✅ 8. 训练模型（线性回归）\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)\n",
        "\n",
        "# ✅ 9. 模型评估（RMSE）\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "print(\"线性回归 RMSE:\", lin_rmse)\n",
        "\n",
        "# ✅ 10. 更复杂的模型（随机森林）\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "forest_reg.fit(housing_prepared, housing_labels)\n",
        "\n",
        "# ✅ 11. 交叉验证评估\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
        "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
        "rmse_scores = np.sqrt(-scores)\n",
        "print(\"随机森林交叉验证 RMSE 平均:\", rmse_scores.mean())\n",
        "\n",
        "# ✅ 12. 最终测试集评估\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "final_predictions = forest_reg.predict(X_test_prepared)\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(\"最终测试集 RMSE:\", final_rmse)\n",
        "\n",
        "# 🎯 本章完成！你现在拥有一个端到端 ML 项目的基本模板。"
      ],
      "metadata": {
        "id": "znBSfA7MfaD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ9rt6lXe9yF"
      },
      "outputs": [],
      "source": [
        "我已经为你创建好了《Hands-On Machine Learning》第三版第 2 章的 Colab 学习模板，内容包含：\n",
        "\t•\t从数据获取到测试集评估的完整流程 ✅\n",
        "\t•\t结构清晰、每步注释齐全 ✅\n",
        "\t•\t可以反复复用，套入新数据集就能做项目 ✅\n",
        "\n",
        "你可以复制这份模板到 Colab 中直接使用，也可以按模块添加笔记和练习。\n",
        "\n",
        "下一步我们可以整理第 3 章（分类问题）、或帮你把这章转成 Markdown 笔记，或者添加“练习题模块”。你想继续哪个？"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A9CeYLMefFoH"
      }
    }
  ]
}